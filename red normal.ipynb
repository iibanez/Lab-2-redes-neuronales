{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iibanez/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier #para implementar el random forest\n",
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "# random seed \n",
    "np.random.seed(3) \n",
    "\n",
    "#activation function\n",
    "def lineal(x):                                        \n",
    "    return x\n",
    "\n",
    "def tanh_array(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "# Helper function to plot a decision boundary. \n",
    "# If you don't fully understand this function don't worry, it just generates the contour plot below. \n",
    "def plot_decision_boundary(pred_func): \n",
    "    # Set min and max values and give it some padding \n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5 \n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5 \n",
    "    h = 0.01 \n",
    "    # Generate a grid of points with distance h between them \n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h)) \n",
    "    #print(xx)\n",
    "    #print(yy)\n",
    "    #print(np.c_[xx.ravel(), yy.ravel()])\n",
    "    # Predict the function value for the whole gid \n",
    "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()]) \n",
    "    #print(Z)\n",
    "    Z = Z.reshape(xx.shape) \n",
    "    # Plot the contour and training examples \n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral) \n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral) \n",
    "\n",
    "#print(\"num_examples\",num_examples)\n",
    "#print(\"nn_input_dim\", nn_input_dim)\n",
    "#print(\"nn_output_dim\", nn_output_dim)\n",
    " \n",
    "# Gradient descent parameters (I picked these by hand) \n",
    "epsilon = 0.01 # learning rate for gradient descent \n",
    "reg_lambda = 0.01 # regularization strength \n",
    "\n",
    "# Helper function to evaluate the total loss on the dataset \n",
    "def calculate_loss(model,X,y, n, e,num_examples): \n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2'] \n",
    "    # Forward propagation to calculate our predictions \n",
    "    z1 = X.dot(W1) + b1\n",
    "    if(n == 0):\n",
    "        a1 = lineal(z1)\n",
    "        #print a1\n",
    "    elif(n == 1):\n",
    "        a1 = tanh_array(z1)\n",
    "    z2 = a1.dot(W2) + b2 \n",
    "    #print \"z2\",z2\n",
    "    exp_scores = np.exp(z2) \n",
    "    #print \"es\",exp_scores\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) \n",
    "    # Calculating the loss \n",
    "    if(e == 0):\n",
    "        corect_logprobs = -np.log(probs[range(num_examples), y])\n",
    "        data_loss = np.sum(corect_logprobs) \n",
    "    elif(e == 1):\n",
    "        #print probs.shape\n",
    "        final = probs[range(num_examples), y]\n",
    "        errores = np.power(final-1,2)\n",
    "        data_loss = np.sum(errores)/num_examples\n",
    "        return data_loss\n",
    "        #print errores\n",
    "    # Add regulatization term to loss (optional) \n",
    "    data_loss += reg_lambda/2 * (np.sum(np.square(W1)) + np.sum(np.square(W2))) \n",
    "    return 1./num_examples * data_loss \n",
    "\n",
    "# Helper function to predict an output (0 or 1) \n",
    "def predict(model, x, n): \n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2'] \n",
    "    # Forward propagation \n",
    "    z1 = x.dot(W1) + b1 \n",
    "    if(n == 0):\n",
    "        a1 = lineal(z1)\n",
    "    elif(n == 1):\n",
    "        a1 = tanh_array(z1)\n",
    "    print(a1)\n",
    "    print(z1)\n",
    "    z2 = a1.dot(W2) + b2 \n",
    "    exp_scores = np.exp(z2) \n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) \n",
    "    return np.argmax(probs, axis=1) \n",
    "\n",
    "# This function learns parameters for the neural network and returns the model. \n",
    "# - nn_hdim: Number of nodes in the hidden layer \n",
    "# - X: data generate model\n",
    "# - y: data predictions model\n",
    "# - n: type function activation\n",
    "# - e: type function error\n",
    "# - num_examples: number the examples \n",
    "# - num_passes: Number of passes through the training data for gradient descent \n",
    "# - print_loss: If True, print the loss every 1000 iterations \n",
    "def build_model(nn_hdim,X,y,n,e, num_examples, nn_input_dim,nn_output_dim,  num_passes=1, print_loss=False): \n",
    " \n",
    "    # Initialize the parameters to random values. We need to learn these. \n",
    "    np.random.seed(0) \n",
    "    W1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim) \n",
    "    b1 = np.zeros((1, nn_hdim)) \n",
    "    W2 = np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim) \n",
    "    b2 = np.zeros((1, nn_output_dim)) \n",
    "\n",
    "    #print(\"W1 shape\", W1.shape)\n",
    "    #print(\"b1 shape\", b1.shape)\n",
    "    #print(\"W2 shape\", W2.shape)\n",
    "    #print(\"b2 shape\", b2.shape)\n",
    " \n",
    "    # This is what we return at the end \n",
    "    model = {} \n",
    "    \n",
    "    #guardar el error\n",
    "    errores = []\n",
    " \n",
    "    # Gradient descent. For each batch... \n",
    "    for i in range(0, num_passes):\n",
    "        # Forward propagation \n",
    "        z1 = X.dot(W1) + b1 \n",
    "        if(n == 0):\n",
    "            a1 = lineal(z1)\n",
    "        elif(n == 1):\n",
    "            a1 = tanh_array(z1)\n",
    "        print(a1)\n",
    "        print(z1)\n",
    "        z2 = a1.dot(W2) + b2 \n",
    "        print(z2)\n",
    "        exp_scores = np.exp(z2) \n",
    "        #super_error \n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) \n",
    "        print(probs)\n",
    "        #print(\"FORWARD STAGE\")\n",
    "        #print(\"z1 shape\",z1.shape)\n",
    "        #print(\"a1 shape\",z1.shape)\n",
    "        #print(\"z1 shape\",z1.shape)\n",
    "        # Backpropagation \n",
    "        delta3 = probs \n",
    "        #print \"1\",delta3\n",
    "        delta3[range(num_examples), y] -= 1 \n",
    "        #print \"2\",delta3\n",
    "        dW2 = (a1.T).dot(delta3) \n",
    "        #print \"dw2\", dW2\n",
    "        db2 = np.sum(delta3, axis=0, keepdims=True) \n",
    "        if(n == 0):\n",
    "            delta2 = delta3.dot(W2.T)\n",
    "        elif (n == 1):\n",
    "            delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2)) \n",
    "        dW1 = np.dot(X.T, delta2) \n",
    "        db1 = np.sum(delta2, axis=0) \n",
    " \n",
    "        # Add regularization terms (b1 and b2 don't have regularization terms) \n",
    "        dW2 += reg_lambda * W2 \n",
    "        dW1 += reg_lambda * W1 \n",
    " \n",
    "        # Gradient descent parameter update \n",
    "        W1 += -epsilon * dW1 \n",
    "        b1 += -epsilon * db1 \n",
    "        W2 += -epsilon * dW2 \n",
    "        b2 += -epsilon * db2 \n",
    " \n",
    "        # Assign new parameters to the model \n",
    "        model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2} \n",
    " \n",
    "        # Optionally print the loss. \n",
    "        # This is expensive because it uses the whole dataset, so we don't want to do it too often. \n",
    "        if print_loss and i % 1000 == 0: \n",
    "            errores.append(calculate_loss(model, X,y, n, e, num_examples))\n",
    "            \n",
    "    return model, errores\n",
    "\n",
    "\n",
    "def validacion_cruzada(data, neu, cil, n, e):\n",
    "    \n",
    "    print \"\"\n",
    "    print \"Comenzando con la generacion del modelo\"\n",
    "    print \"neuronas: %i, funcion transferencia: %i, funcion objetivo: %i\"%(neu,n,e)\n",
    "    \n",
    "    #todas las columnas\n",
    "    #x_total= pandas.DataFrame.as_matrix(data.loc[:, 'est_civil':])\n",
    "    #y_total = np.array(data['status_salud_publica'])\n",
    "\n",
    "    #cv = cross_validation.KFold(len(data), n_folds=10)\n",
    "    X, x_test, Y, y_test = train_test_split(data.loc[:, \"est_civil\":], data['status_salud_publica'], test_size=0.3)\n",
    "\n",
    "    vp = 0\n",
    "    vn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    it = 0\n",
    "    errores = []\n",
    "\n",
    "    #se inicia la validacion cruzada\n",
    "    #for traincv, testcv in cv:\n",
    "        \n",
    "    X = pandas.DataFrame.as_matrix(X)\n",
    "    x_test = pandas.DataFrame.as_matrix(x_test)\n",
    "\n",
    "    y = np.array(Y).astype(int)\n",
    "\n",
    "    y_test = np.array(y_test).astype(int)\n",
    "\n",
    "    # %% 15 \n",
    "    num_examples = len(X) # training set size \n",
    "    print(num_examples)\n",
    "    nn_input_dim = len(X[0]) # input layer dimensionality \n",
    "    print(nn_input_dim)\n",
    "    nn_output_dim = 2 # output layer dimensionality \n",
    "\n",
    "    print \"iteracion: %i\"%(it)\n",
    "    # %% 17 \n",
    "    # Build a model with a 3-dimensional hidden layer \n",
    "    #for p in range\n",
    "    model, err = build_model(neu,X,y, n,e, num_examples, nn_input_dim,nn_output_dim, num_passes=cil, print_loss=True) \n",
    "    #   print err\n",
    "    errores.append(err)\n",
    "    \n",
    "    solv = predict(model, x_test, n)\n",
    "    \n",
    "    p = pandas.crosstab(y_test, solv, rownames=['Clase real'], colnames=['Prediccion clase'])\n",
    "    \n",
    "    try:\n",
    "        vp += p[0][0]\n",
    "        fn += p[0][1]\n",
    "        fp += p[1][0]\n",
    "        vn += p[1][1]\n",
    "    except:\n",
    "        vp += p[0][0]\n",
    "        fp += 0\n",
    "        fn += p[0][1]\n",
    "        vn += 0\n",
    "\n",
    "    it+=1\n",
    "\n",
    "    #pro = []\n",
    "    #for i in range(0,cil/1000):\n",
    "    #    suma = 0\n",
    "    #    for j in range(10):\n",
    "    #        suma+=errores[j][i]\n",
    "    #    pro.append(suma/10.0)\n",
    "\n",
    "    #son mostrados los resultados\n",
    "    print \"Exactitud: \",(vp+vn)/float(vp+vn+fp+fn)\n",
    "    print \"%i | %i\"%(vp,fp)\n",
    "    print \"%i | %i\"%(fn,vn)\n",
    "\n",
    "    return (vp+vn)/float(vp+vn+fp+fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('./NO_C_2017.csv')\n",
    "data1 = pandas.read_csv('./A.csv')\n",
    "data2 = pandas.read_csv('./B.csv')\n",
    "data3 = pandas.read_csv('./C.csv')\n",
    "data4 = pandas.read_csv('./D.csv')\n",
    "\n",
    "#unir \n",
    "datos = pandas.concat([data, data1, data2, data3, data4])\n",
    "\n",
    "#mesclar los datos\n",
    "datos = datos.sample(frac = 1)\n",
    "datos = datos.sample(frac = 1)\n",
    "datos = datos.sample(frac = 1)\n",
    "\n",
    "selectOpt = [\"status_salud_publica\",\"est_civil\",\"sexo_desc\",\"edad\",\"estrato\",\n",
    "\"ind_interd\",\"comuna\",\"ind_region_rm\",\"avaluo_bbrr\",\"cant_bbrr\",\"avaluo_auto\",\"cant_autos\",\n",
    "\"n_actividad\",\"n_rubros\",\"clean2\",\"tot_docs\",\"tot_mont\",\"ind_morosidad1\",\"ind_morosidad2\",\"ind_consultas_id\",\n",
    "\"cant_personas_fam\",\"cant_hijos_fam\"]\n",
    "\n",
    "\n",
    "#selectOpt = [\"status_salud_publica\",\"edad\",\"estrato\"]\n",
    "\n",
    "datos.loc[((datos[\"est_civil\"] == \" \") & (datos[\"cant_hijos_fam\"] == 0)), \"est_civil\"] = \"SOLTERO\"\n",
    "datos.loc[((datos[\"est_civil\"] == \" \") & (datos[\"cant_hijos_fam\"] > 0)), \"est_civil\"] = \"CASADO\"\n",
    "\n",
    "#son pasados los estados a una variable binaria\n",
    "datos.loc[datos[\"status_salud_publica\"] == \"S\", \"status_salud_publica\"]= 1\n",
    "datos.loc[datos[\"status_salud_publica\"] == \"N\", \"status_salud_publica\"]= 0\n",
    "\n",
    "#cambair sexo de la persona\n",
    "datos.loc[datos[\"sexo_desc\"] == \"F\", \"sexo_desc\"]= 0\n",
    "datos.loc[datos[\"sexo_desc\"] == \"M\", \"sexo_desc\"]= 1\n",
    "datos.loc[datos[\"sexo_desc\"] == \"SI\" , \"sexo_desc\"] = 0\n",
    "\n",
    "#ind_interd\n",
    "datos.loc[datos[\"ind_interd\"] == \" \" , \"ind_interd\"] = 0\n",
    "datos.loc[datos[\"ind_interd\"] == \"N\" , \"ind_interd\"] = 0\n",
    "datos.loc[datos[\"ind_interd\"] == \"S\" , \"ind_interd\"] = 1\n",
    "\n",
    "#gente de fuera de santiago agregar comuna\n",
    "datos.loc[datos[\"est_civil\"] == \"SOLTERO\", \"est_civil\"]= 0\n",
    "datos.loc[datos[\"est_civil\"] == \"CASADO\", \"est_civil\"]= 3\n",
    "datos.loc[datos[\"est_civil\"] == \"VIUDO\", \"est_civil\"]= 1\n",
    "datos.loc[datos[\"est_civil\"] == \"DIVORCIADO\", \"est_civil\"]= 2\n",
    "datos.loc[datos[\"est_civil\"] == \"SEPARADO JUDICIALMENTE\", \"est_civil\"]= 2\n",
    "\n",
    "#son discretizados los estratos sociales\n",
    "datos.loc[datos[\"estrato\"] == \"SIN CLASIFICACION\", \"estrato\"]= 3\n",
    "datos.loc[datos[\"estrato\"] == \"ABC1\", \"estrato\"]= 5\n",
    "datos.loc[datos[\"estrato\"] == \"C2\", \"estrato\"]= 4\n",
    "datos.loc[datos[\"estrato\"] == \"C3\", \"estrato\"]= 3\n",
    "datos.loc[datos[\"estrato\"] == \"D\", \"estrato\"]= 2\n",
    "datos.loc[datos[\"estrato\"] == \"E\", \"estrato\"]= 1\n",
    "\n",
    "datos = datos.loc[:,selectOpt]\n",
    "\n",
    "#se indica que son columnas enteras\n",
    "for name in selectOpt[1:len(selectOpt)]:\n",
    "    #print(name\n",
    "    datos[name] = datos[name].astype('float')\n",
    "    #datos[name] = datos[name] + 2\n",
    "\n",
    "#datos.loc[:, 'est_civil':] = (datos.loc[:, 'est_civil':] - datos.loc[:, 'est_civil':].mean()) / (datos.loc[:, 'est_civil':].max() - datos.loc[:, 'est_civil':].min())\n",
    "\n",
    "\n",
    "datos = datos.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comenzando con la generacion del modelo\n",
      "neuronas: 100, funcion transferencia: 1, funcion objetivo: 0\n",
      "621250\n",
      "21\n",
      "iteracion: 0\n",
      "[[-1.         -1.         -1.         ..., -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         ..., -1.         -1.         -1.        ]\n",
      " [-0.98100877 -0.71405856  0.99999289 ...,  0.9999997  -0.99999775\n",
      "   0.84760275]\n",
      " ..., \n",
      " [-1.         -1.         -1.         ..., -1.         -1.         -1.        ]\n",
      " [-1.         -1.          1.         ...,  1.         -1.         -1.        ]\n",
      " [-1.         -1.          1.         ...,  1.         -1.         -1.        ]]\n",
      "[[ -2.50756107e+06  -1.96143528e+06  -1.06856077e+06 ...,  -1.56436605e+06\n",
      "   -9.21854353e+05  -1.31633499e+06]\n",
      " [ -1.37117456e+06  -1.14874242e+06  -7.48389438e+05 ...,  -1.02210417e+06\n",
      "   -4.02988343e+05  -7.87588648e+05]\n",
      " [ -2.32369203e+00  -8.95416121e-01   6.27386821e+00 ...,   7.86368634e+00\n",
      "   -6.84904456e+00   1.24757684e+00]\n",
      " ..., \n",
      " [ -6.86314113e+06  -5.74980501e+06  -3.74597797e+06 ...,  -5.11596249e+06\n",
      "   -2.01705889e+06  -3.94213422e+06]\n",
      " [ -4.36468954e+05  -2.04094919e+05   1.09817847e+05 ...,   2.83891459e+04\n",
      "   -3.42932391e+05  -1.07025697e+05]\n",
      " [ -9.95807908e+05  -4.65593763e+05   2.50398416e+05 ...,   6.41729225e+04\n",
      "   -7.81812510e+05  -2.43963379e+05]]\n",
      "[[ 0.74983071  0.26059455]\n",
      " [ 0.99799067  0.41553127]\n",
      " [ 0.5471182   1.048926  ]\n",
      " ..., \n",
      " [ 0.99799067  0.41553127]\n",
      " [-0.13290528  1.59990621]\n",
      " [-0.13290528  1.59990621]]\n",
      "[[ 0.61992647  0.38007353]\n",
      " [ 0.64163312  0.35836688]\n",
      " [ 0.37711592  0.62288408]\n",
      " ..., \n",
      " [ 0.64163312  0.35836688]\n",
      " [ 0.15022831  0.84977169]\n",
      " [ 0.15022831  0.84977169]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iibanez/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:53: RuntimeWarning: overflow encountered in exp\n",
      "/Users/iibanez/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "/Users/iibanez/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:58: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -1.         -1.         ..., -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         ..., -1.         -1.         -1.        ]\n",
      " [ 1.          1.         -0.99999946 ...,  1.          1.         -1.        ]\n",
      " ..., \n",
      " [-1.         -1.         -1.         ..., -1.         -1.         -1.        ]\n",
      " [-1.         -1.          1.         ...,  1.         -1.         -1.        ]\n",
      " [-1.         -1.          1.         ...,  1.         -1.         -1.        ]]\n",
      "[[ -2.50712171e+06  -1.93322194e+06  -1.06848128e+06 ...,  -1.56356294e+06\n",
      "   -9.02917678e+05  -1.31887037e+06]\n",
      " [ -1.37083105e+06  -1.13039780e+06  -7.48338564e+05 ...,  -1.02153255e+06\n",
      "   -3.90445272e+05  -7.89145556e+05]\n",
      " [  4.75294575e+01   1.10841764e+04  -7.55960583e+00 ...,   2.79577652e+02\n",
      "    7.42463823e+03  -8.81889773e+02]\n",
      " ..., \n",
      " [ -6.86224279e+06  -5.71710778e+06  -3.74563601e+06 ...,  -5.11469491e+06\n",
      "   -1.99524324e+06  -3.94480850e+06]\n",
      " [ -4.38051067e+05  -1.79601087e+05   1.09692937e+05 ...,   2.88423663e+04\n",
      "   -3.30195479e+05  -9.63469646e+04]\n",
      " [ -9.95617361e+05  -4.51901094e+05   2.50356289e+05 ...,   6.45246068e+04\n",
      "   -7.72554153e+05  -2.45282498e+05]]\n",
      "[[ -4781.38762829   4781.71524365]\n",
      " [ -5887.96340044   5888.62864055]\n",
      " [  4342.67909638  -4341.00072681]\n",
      " ..., \n",
      " [ -4300.31771451   4300.86488663]\n",
      " [ 18990.50250264 -18987.75328514]\n",
      " [ 21117.3153294  -21114.65393883]]\n",
      "[[  0.  nan]\n",
      " [  0.  nan]\n",
      " [ nan   0.]\n",
      " ..., \n",
      " [  0.  nan]\n",
      " [ nan   0.]\n",
      " [ nan   0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iibanez/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:128: RuntimeWarning: overflow encountered in exp\n",
      "/Users/iibanez/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:130: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bf48d6ca44f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#df = df.append({'neuronas':80,'ciclos':cil,'n': 1,'e': 0,'exactitud':validacion_cruzada(data, 80, cil, 1, 0)  }, ignore_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#df = df.append({'neuronas':90,'ciclos':cil,'n': 1,'e': 1,'exactitud':validacion_cruzada(data, 90, cil, 1, 1)  }, ignore_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'neuronas'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ciclos'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcil\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'e'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'exactitud'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvalidacion_cruzada\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#df = df.append({'neuronas':110,'ciclos':cil,'n': 0,'e': 1,'exactitud':validacion_cruzada(data, 110, cil, 0, 1)  }, ignore_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#df = df.append({'neuronas':120,'ciclos':cil,'n': 1,'e': 1,'exactitud':validacion_cruzada(data, 120, cil, 1, 1)  }, ignore_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-df8c4e00ef55>\u001b[0m in \u001b[0;36mvalidacion_cruzada\u001b[0;34m(data, neu, cil, n, e)\u001b[0m\n\u001b[1;32m    211\u001b[0m    \u001b[0;31m# Build a model with a 3-dimensional hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m    \u001b[0;31m#for p in range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m    \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_input_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn_output_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_passes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m    \u001b[0;31m#   print err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m    \u001b[0merrores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-df8c4e00ef55>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(nn_hdim, X, y, n, e, num_examples, nn_input_dim, nn_output_dim, num_passes, print_loss)\u001b[0m\n\u001b[1;32m    117\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_passes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m        \u001b[0;31m# Forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m        \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m        \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m            \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlineal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#implementar cross-validation\n",
    "df = pandas.DataFrame(columns=['neuronas','ciclos','n','e','exactitud'],dtype=float)\n",
    "\n",
    "data = datos\n",
    "\n",
    "cil = 200 #numero de ciclos\n",
    "#df = df.append({'neuronas':10,'ciclos':cil,'n': 0,'e': 1,'exactitud':validacion_cruzada(data, 10, cil, 0, 1)  }, ignore_index=True)\n",
    "#df = df.append({'neuronas':20,'ciclos':cil,'n': 0,'e': 0,'exactitud':validacion_cruzada(data, 20, cil, 0, 0)  }, ignore_index=True)\n",
    "#df = df.append({'neuronas':30,'ciclos':cil,'n': 1,'e': 0,'exactitud':validacion_cruzada(data, 30, cil, 1, 0)  }, ignore_index=True)\n",
    "#df = df.append({'neuronas':40,'ciclos':cil,'n': 0,'e': 1,'exactitud':validacion_cruzada(data, 40, cil, 0, 1)  }, ignore_index=True)\n",
    "#df = df.append({'neuronas':50,'ciclos':cil,'n': 1,'e': 1,'exactitud':validacion_cruzada(data, 50, cil, 1, 1)  }, ignore_index=True)\n",
    "#df = df.append({'neuronas':60,'ciclos':cil,'n': 1,'e': 0,'exactitud':validacion_cruzada(data, 60, cil, 1, 0)  }, ignore_index=True)\n",
    "#df = df.append({'neuronas':70,'ciclos':cil,'n': 1,'e': 0,'exactitud':validacion_cruzada(data, 70, cil, 1, 0)  }, ignore_index=True)\n",
    "#df = df.append({'neuronas':80,'ciclos':cil,'n': 1,'e': 0,'exactitud':validacion_cruzada(data, 80, cil, 1, 0)  }, ignore_index=True)\n",
    "#df = df.append({'neuronas':90,'ciclos':cil,'n': 1,'e': 1,'exactitud':validacion_cruzada(data, 90, cil, 1, 1)  }, ignore_index=True)\n",
    "df = df.append({'neuronas':100,'ciclos':cil,'n': 0,'e': 0,'exactitud':validacion_cruzada(data, 100, cil, 1, 0)  }, ignore_index=True)\n",
    "#df = df.append({'neuronas':110,'ciclos':cil,'n': 0,'e': 1,'exactitud':validacion_cruzada(data, 110, cil, 0, 1)  }, ignore_index=True)\n",
    "#df = df.append({'neuronas':120,'ciclos':cil,'n': 1,'e': 1,'exactitud':validacion_cruzada(data, 120, cil, 1, 1)  }, ignore_index=True)\n",
    "#df = df.append({'neuronas':40,'ciclos':cil,'n': 0,'e': 1,'exactitud':validacion_cruzada(data, 40, cil, 0, 1)  }, ignore_index=True)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_salud_publica</th>\n",
       "      <th>est_civil</th>\n",
       "      <th>sexo_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887470</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887471</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887472</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887473</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887474</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887475</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887476</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887477</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887478</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887479</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887480</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887481</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887482</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887483</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887484</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887485</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887486</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887487</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887488</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887489</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887490</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887491</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887492</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887493</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887494</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887495</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887496</th>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887497</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887498</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887499</th>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       status_salud_publica  est_civil  sexo_desc\n",
       "0                         1        0.1        1.1\n",
       "1                         0        0.1        0.1\n",
       "2                         1        0.1        0.1\n",
       "3                         1        3.1        0.1\n",
       "4                         1        3.1        0.1\n",
       "5                         1        3.1        0.1\n",
       "6                         0        0.1        0.1\n",
       "7                         0        0.1        0.1\n",
       "8                         0        3.1        1.1\n",
       "9                         0        0.1        1.1\n",
       "10                        1        3.1        1.1\n",
       "11                        0        0.1        1.1\n",
       "12                        1        0.1        0.1\n",
       "13                        0        3.1        1.1\n",
       "14                        1        1.1        1.1\n",
       "15                        1        3.1        0.1\n",
       "16                        0        0.1        0.1\n",
       "17                        0        0.1        1.1\n",
       "18                        0        0.1        1.1\n",
       "19                        0        0.1        1.1\n",
       "20                        0        3.1        0.1\n",
       "21                        1        0.1        0.1\n",
       "22                        1        3.1        1.1\n",
       "23                        0        0.1        1.1\n",
       "24                        0        0.1        0.1\n",
       "25                        1        3.1        1.1\n",
       "26                        0        0.1        1.1\n",
       "27                        0        3.1        1.1\n",
       "28                        1        3.1        0.1\n",
       "29                        1        3.1        0.1\n",
       "...                     ...        ...        ...\n",
       "887470                    1        3.1        1.1\n",
       "887471                    0        3.1        0.1\n",
       "887472                    1        0.1        0.1\n",
       "887473                    1        0.1        1.1\n",
       "887474                    0        3.1        0.1\n",
       "887475                    1        0.1        0.1\n",
       "887476                    1        0.1        1.1\n",
       "887477                    0        3.1        0.1\n",
       "887478                    0        0.1        1.1\n",
       "887479                    0        3.1        0.1\n",
       "887480                    1        3.1        1.1\n",
       "887481                    0        0.1        0.1\n",
       "887482                    0        0.1        1.1\n",
       "887483                    0        0.1        1.1\n",
       "887484                    1        3.1        0.1\n",
       "887485                    0        0.1        1.1\n",
       "887486                    0        3.1        1.1\n",
       "887487                    1        0.1        0.1\n",
       "887488                    0        0.1        1.1\n",
       "887489                    0        0.1        1.1\n",
       "887490                    0        3.1        1.1\n",
       "887491                    1        3.1        1.1\n",
       "887492                    0        0.1        1.1\n",
       "887493                    0        3.1        0.1\n",
       "887494                    1        3.1        1.1\n",
       "887495                    0        3.1        1.1\n",
       "887496                    0        3.1        1.1\n",
       "887497                    1        3.1        1.1\n",
       "887498                    1        0.1        0.1\n",
       "887499                    1        3.1        0.1\n",
       "\n",
       "[887500 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-20ba0b27b519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'exp_scores' is not defined"
     ]
    }
   ],
   "source": [
    "np.sum(exp_scores, axis=1, keepdims=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
